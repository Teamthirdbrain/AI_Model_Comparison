import streamlit as st
from difflib import SequenceMatcher
from transformers import pipeline, GPT2Tokenizer

# AI models and their respective names
models = {
    "gpt2": "GPT-2",
    "gpt2-medium": "GPT-2 Medium",
    "gpt2-large": "GPT-2 Large",
    # Add more models here as per your requirements
}

# Load the models and their tokenizers
tokenizer_models = {model_name: GPT2Tokenizer.from_pretrained(model_name) for model_name in models}
generation_models = {model_name: pipeline("text-generation", model=model_name, tokenizer=tokenizer_models[model_name]) for model_name in models}


# Streamlit app
st.title("·¥Ä…™ ·¥ç·¥è·¥Ö·¥á ü ·¥Ñ·¥è·¥ç·¥ò·¥Ä Ä…™Íú±·¥è…¥")

# Model selection
selected_models = st.multiselect("Íú±·¥á ü·¥á·¥Ñ·¥õ ·¥Ä…™ ·¥ç·¥è·¥Ö·¥á üÍú± ·¥õ·¥è ·¥Ñ·¥è·¥ç·¥ò·¥Ä Ä·¥á:", list(models.keys()))

# Input query
benchmark_query = st.text_input("·¥á…¥·¥õ·¥á Ä  è·¥è·¥ú Ä  ô·¥á…¥·¥Ñ ú·¥ç·¥Ä Ä·¥ã Q·¥ú·¥á Ä è ·¥è Ä ·¥Ö·¥Ä·¥õ·¥Ä:")

if benchmark_query and len(selected_models) == 2:
    # Generate outputs using the selected models
    output_a = generation_models[selected_models[0]](benchmark_query, max_length=100, num_return_sequences=1)
    output_b = generation_models[selected_models[1]](benchmark_query, max_length=100, num_return_sequences=1)

    # Extract the generated text from the output
    output_a_text = output_a[0]["generated_text"].strip()
    output_b_text = output_b[0]["generated_text"].strip()

    # Compare and evaluate the outputs
    similarity_a = SequenceMatcher(None, benchmark_query, output_a_text).ratio()
    similarity_b = SequenceMatcher(None, benchmark_query, output_b_text).ratio()

    # Display the results
    st.subheader("·¥Ñ·¥è·¥ç·¥ò·¥Ä Ä…™Íú±·¥è…¥  Ä·¥áÍú±·¥ú ü·¥õÍú±:")

    st.markdown(
        f"<div style='display:flex; gap:20px;'>"
        f"<div style='flex:1; background-color:#2E1813; padding:20px; border-radius:10px;'>"
        f"<h3>{models[selected_models[0]]}</h3>"
        f"<p>{output_a_text}</p>"
        f"</div>"
        f"<div style='flex:1; background-color:#2E1813; padding:20px; border-radius:10px;'>"
        f"<h3>{models[selected_models[1]]}</h3>"
        f"<p>{output_b_text}</p>"
        f"</div>"
        f"</div>",
        unsafe_allow_html=True
    )

    st.subheader("Íú±…™·¥ç…™ ü·¥Ä Ä…™·¥õ è Íú±·¥Ñ·¥è Ä·¥áÍú±:")

    st.markdown(
        f"<div style='display:flex; gap:20px;'>"
        f"<div style='background-color:#2E1813; padding:20px; border-radius:10px;'>"
        f"<p>Similarity Score ({models[selected_models[0]]}): {similarity_a}</p>"
        f"</div>"
        f"<div style='background-color:#2E1813; padding:20px; border-radius:10px;'>"
        f"<p>Similarity Score ({models[selected_models[1]]}): {similarity_b}</p>"
        f"</div>"
        f"</div>",
        unsafe_allow_html=True
    )

    st.subheader(" Ä·¥á·¥Ñ·¥è·¥ç·¥ç·¥á…¥·¥Ö·¥Ä·¥õ…™·¥è…¥:")
    if similarity_a > similarity_b:
        st.success(f"{models[selected_models[0]]}·¥ò Ä·¥è·¥†…™·¥Ö·¥áÍú± ·¥Ä ·¥ç·¥è Ä·¥á  Ä·¥á ü·¥á·¥†·¥Ä…¥·¥õ ·¥Ä…¥Íú±·¥°·¥á Ä.")
        st.success(f"Recommendation: Use {models[selected_models[0]]} for this task.")
    elif similarity_a < similarity_b:
        st.success(f"{models[selected_models[1]]}·¥ò Ä·¥è·¥†…™·¥Ö·¥áÍú± ·¥Ä ·¥ç·¥è Ä·¥á  Ä·¥á ü·¥á·¥†·¥Ä…¥·¥õ ·¥Ä…¥Íú±·¥°·¥á Ä.")
        st.success(f"Recommendation: Use {models[selected_models[1]]} for this task.")
    else:
        st.success("‚Äãüáß‚Äã‚Äãüá¥‚Äã‚Äãüáπ‚Äã‚Äãüá≠‚Äã ‚Äãüá¶‚Äã‚ÄãüáÆ‚Äã ‚Äãüá≤‚Äã‚Äãüá¥‚Äã‚Äãüá©‚Äã‚Äãüá™‚Äã‚Äãüá±‚Äã‚Äãüá∏‚Äã ‚Äãüáµ‚Äã‚Äãüá∑‚Äã‚Äãüá¥‚Äã‚Äãüáª‚Äã‚ÄãüáÆ‚Äã‚Äãüá©‚Äã‚Äãüá™‚Äã ‚Äãüá∏‚Äã‚ÄãüáÆ‚Äã‚Äãüá≤‚Äã‚ÄãüáÆ‚Äã‚Äãüá±‚Äã‚Äãüá¶‚Äã‚Äãüá∑‚Äã ‚Äãüá±‚Äã‚Äãüá™‚Äã‚Äãüáª‚Äã‚Äãüá™‚Äã‚Äãüá±‚Äã‚Äãüá∏‚Äã ‚Äãüá¥‚Äã‚Äãüá´‚Äã ‚Äãüá∑‚Äã‚Äãüá™‚Äã‚Äãüá±‚Äã‚Äãüá™‚Äã‚Äãüáª‚Äã‚Äãüá¶‚Äã‚Äãüá≥‚Äã‚Äãüá®‚Äã‚Äãüá™‚Äã.")
        st.success("‚Äãüá∑‚Äã‚Äãüá™‚Äã‚Äãüá®‚Äã‚Äãüá¥‚Äã‚Äãüá≤‚Äã‚Äãüá≤‚Äã‚Äãüá™‚Äã‚Äãüá≥‚Äã‚Äãüá©‚Äã‚Äãüá¶‚Äã‚Äãüáπ‚Äã‚ÄãüáÆ‚Äã‚Äãüá¥‚Äã‚Äãüá≥‚Äã‚¶Ç ‚Äãüáæ‚Äã‚Äãüá¥‚Äã‚Äãüá∫‚Äã ‚Äãüá®‚Äã‚Äãüá¶‚Äã‚Äãüá≥‚Äã ‚Äãüá®‚Äã‚Äãüá≠‚Äã‚Äãüá¥‚Äã‚Äãüá¥‚Äã‚Äãüá∏‚Äã‚Äãüá™‚Äã ‚Äãüá™‚Äã‚ÄãüáÆ‚Äã‚Äãüáπ‚Äã‚Äãüá≠‚Äã‚Äãüá™‚Äã‚Äãüá∑‚Äã ‚Äãüá≤‚Äã‚Äãüá¥‚Äã‚Äãüá©‚Äã‚Äãüá™‚Äã‚Äãüá±‚Äã ‚Äãüá´‚Äã‚Äãüá¥‚Äã‚Äãüá∑‚Äã ‚Äãüáπ‚Äã‚Äãüá≠‚Äã‚ÄãüáÆ‚Äã‚Äãüá∏‚Äã ‚Äãüáπ‚Äã‚Äãüá¶‚Äã‚Äãüá∏‚Äã‚Äãüá∞‚Äã.")
elif benchmark_query or len(selected_models) == 2:
    st.warning("üáµ‚Äã‚Äãüá±‚Äã‚Äãüá™‚Äã‚Äãüá¶‚Äã‚Äãüá∏‚Äã‚Äãüá™‚Äã ‚Äãüá™‚Äã‚Äãüá≥‚Äã‚Äãüáπ‚Äã‚Äãüá™‚Äã‚Äãüá∑‚Äã ‚Äãüá¶‚Äã ‚Äãüáß‚Äã‚Äãüá™‚Äã‚Äãüá≥‚Äã‚Äãüá®‚Äã‚Äãüá≠‚Äã‚Äãüá≤‚Äã‚Äãüá¶‚Äã‚Äãüá∑‚Äã‚Äãüá∞‚Äã ‚Äãüá∂‚Äã‚Äãüá∫‚Äã‚Äãüá™‚Äã‚Äãüá∑‚Äã‚Äãüáæ‚Äã ‚Äãüá¶‚Äã‚Äãüá≥‚Äã‚Äãüá©‚Äã ‚Äãüá∏‚Äã‚Äãüá™‚Äã‚Äãüá±‚Äã‚Äãüá™‚Äã‚Äãüá®‚Äã‚Äãüáπ‚Äã ‚Äãüá™‚Äã‚ÄãüáΩ‚Äã‚Äãüá¶‚Äã‚Äãüá®‚Äã‚Äãüáπ‚Äã‚Äãüá±‚Äã‚Äãüáæ‚Äã ‚Äãüáπ‚Äã‚Äãüáº‚Äã‚Äãüá¥‚Äã ‚Äãüá≤‚Äã‚Äãüá¥‚Äã‚Äãüá©‚Äã‚Äãüá™‚Äã‚Äãüá±‚Äã‚Äãüá∏‚Äã.")
